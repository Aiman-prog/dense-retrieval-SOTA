{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addb119c",
   "metadata": {},
   "source": [
    "# BRIGHT Benchmark - Steps 1-3 Demo\n",
    "\n",
    "## Step 1: Setup \n",
    "- Dependencies installed\n",
    "- Project structure created  \n",
    "- Config file ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf727f",
   "metadata": {},
   "source": [
    "## Step 2: Load BRIGHT Dataset (for document lookup) and ReasonIR-HQ (for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61687a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step 2A: Loading BRIGHT dataset for document lookup...\n",
      "================================================================================\n",
      "Loading BRIGHT 'documents' from: xlangai/BRIGHT\n",
      "Using cache directory: /Users/aiamn/scratch/aiamn/dense-retrieval-SOTA/data/bright\n",
      "Loading BRIGHT 'Gemini-1.0_reason' (queries/qrels) from: xlangai/BRIGHT\n",
      "Loaded Documents Domains: ['psychology', 'sustainable_living', 'earth_science', 'stackoverflow', 'biology', 'economics', 'pony', 'leetcode', 'theoremqa_theorems', 'robotics', 'aops', 'theoremqa_questions']\n",
      "Loaded Examples Domains: ['psychology', 'sustainable_living', 'earth_science', 'stackoverflow', 'biology', 'economics', 'pony', 'leetcode', 'theoremqa_theorems', 'robotics', 'aops', 'theoremqa_questions']\n",
      "\n",
      "✅ BRIGHT dataset loaded!\n",
      "Available domains in documents: ['biology', 'earth_science', 'economics', 'psychology', 'robotics']...\n",
      "Available domains in examples: ['biology', 'earth_science', 'economics', 'psychology', 'robotics']...\n",
      "\n",
      "================================================================================\n",
      "Creating BRIGHT document ID-to-text mapping...\n",
      "================================================================================\n",
      "Created ID-to-text mapping for 1145164 documents across 12 domains\n",
      "✅ Created mapping for 1145164 documents\n",
      "\n",
      "================================================================================\n",
      "Step 2B: ReasonIR-HQ dataset configuration...\n",
      "================================================================================\n",
      "Dataset: reasonir/reasonir-data\n",
      "Subset: hq\n",
      "Cache dir: data/reasonir\n",
      "✅ ReasonIR-HQ will be loaded during preprocessing (Step 3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd() / 'src'))\n",
    "\n",
    "from data.bright_loader import BRIGHTLoader\n",
    "from utils.helpers import load_config\n",
    "\n",
    "# Load config\n",
    "config = load_config('config/config.yaml')\n",
    "\n",
    "# Step 2A: Load BRIGHT dataset (needed for document ID mapping)\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 2A: Loading BRIGHT dataset for document lookup...\")\n",
    "print(\"=\" * 80)\n",
    "loader = BRIGHTLoader(config_path='config/config.yaml')\n",
    "dataset = loader.load_dataset()\n",
    "\n",
    "print(f\"\\n✅ BRIGHT dataset loaded!\")\n",
    "print(f\"Available domains in documents: {list(loader.documents_dataset.keys())[:5]}...\")\n",
    "print(f\"Available domains in examples: {list(loader.examples_dataset.keys())[:5]}...\")\n",
    "\n",
    "# Create ID-to-text mapping (needed for ReasonIR-HQ)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating BRIGHT document ID-to-text mapping...\")\n",
    "print(\"=\" * 80)\n",
    "id2doc = loader.get_all_documents_id_map()\n",
    "print(f\"✅ Created mapping for {len(id2doc)} documents\")\n",
    "\n",
    "# Step 2B: ReasonIR-HQ dataset configuration\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 2B: ReasonIR-HQ dataset configuration...\")\n",
    "print(\"=\" * 80)\n",
    "reasonir_config = config['dataset']['reasonir']\n",
    "print(f\"Dataset: {reasonir_config['name']}\")\n",
    "print(f\"Subset: {reasonir_config['subset']}\")\n",
    "print(f\"Cache dir: {reasonir_config['cache_dir']}\")\n",
    "print(f\"✅ ReasonIR-HQ will be loaded during preprocessing (Step 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ba0e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Loading ReasonIR-HQ dataset...\n",
      "================================================================================\n",
      "\n",
      "✅ ReasonIR-HQ dataset loaded!\n",
      "  - Total examples: 100521\n",
      "  - Dataset structure: ['query', 'pos', 'neg']\n",
      "\n",
      "================================================================================\n",
      "Sample ReasonIR-HQ entry (before mapping):\n",
      "================================================================================\n",
      "Query sequence: ['Given this reasoning-intensive query, find relevant documents that could help answer the question. ', 'A researcher is analyzing a sound signal represented by the equation f(t) = 2sin(3πt) + sin(5πt) + 0.5sin(7πt). Using the Fourier transform, what are the frequencies, amplitudes, and phases of the individual sinusoidal components in the signal?']\n",
      "Query (actual): A researcher is analyzing a sound signal represented by the equation f(t) = 2sin(3πt) + sin(5πt) + 0.5sin(7πt). Using the Fourier transform, what are the frequencies, amplitudes, and phases of the individual sinusoidal components in the signal?\n",
      "Positive document IDs: [['', 'camel_44852']]\n",
      "Negative document IDs: [['', 'The Fourier transform is widely used in various fields, including engineering, physics, and data analysis. It is a powerful tool for decomposing a signal into its constituent frequencies. In music, for example, the Fourier transform can be used to analyze the frequency components of a sound wave. By applying the Fourier transform to a sound signal, one can identify the different frequencies present in the signal, as well as their relative amplitudes. This information can be useful in a variety of applications, such as sound filtering and audio processing. The Fourier transform can also be used to analyze images and other types of data. In image processing, the Fourier transform can be used to filter out noise and other unwanted features from an image. It can also be used to compress images by representing them in the frequency domain. In addition to its many practical applications, the Fourier transform also has a number of interesting theoretical properties. For example, it has been shown that the Fourier transform is a linear transformation, meaning that it preserves the operations of addition and scalar multiplication. This property makes the Fourier transform a useful tool for solving systems of linear equations. Despite its many uses and interesting properties, the Fourier transform is not without its limitations. For example, it is not suitable for analyzing signals that are non-stationary, meaning that their frequency content changes over time. In such cases, other transforms, such as the wavelet transform, may be more effective. In conclusion, the Fourier transform is a powerful tool with a wide range of applications in many fields. Its ability to decompose signals into their constituent frequencies makes it a valuable tool for data analysis, filtering, and compression.']]\n",
      "\n",
      "✅ Mapped document ID 'camel_44852' to text:\n",
      "Document text (first 200 chars): A sound signal is given by the equation f(t) = sin(2πt) + sin(4πt) + sin(6πt) where t is time in seconds. Use Fourier transform to find the frequencies, amplitudes, and phases of the individual sinuso...\n"
     ]
    }
   ],
   "source": [
    "# Extract and explore ReasonIR-HQ dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Loading ReasonIR-HQ dataset...\")\n",
    "print(\"=\" * 80)\n",
    "reasonir_config = config['dataset']['reasonir']\n",
    "hq_dataset = load_dataset(\n",
    "    reasonir_config['name'],\n",
    "    reasonir_config['subset'],\n",
    "    cache_dir=reasonir_config.get('cache_dir')\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ ReasonIR-HQ dataset loaded!\")\n",
    "print(f\"  - Total examples: {len(hq_dataset['train'])}\")\n",
    "print(f\"  - Dataset structure: {list(hq_dataset['train'][0].keys())}\")\n",
    "\n",
    "# Show sample entry\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Sample ReasonIR-HQ entry (before mapping):\")\n",
    "print(\"=\" * 80)\n",
    "sample_entry = hq_dataset['train'][0]\n",
    "print(f\"Query sequence: {sample_entry['query']}\")\n",
    "print(f\"Query (actual): {sample_entry['query'][1] if len(sample_entry['query']) > 1 else sample_entry['query'][0]}\")\n",
    "print(f\"Positive document IDs: {sample_entry['pos']}\")\n",
    "print(f\"Negative document IDs: {sample_entry['neg']}\")\n",
    "\n",
    "# Map one document ID to show actual text\n",
    "if sample_entry['pos'] and len(sample_entry['pos']) > 0:\n",
    "    first_pos = sample_entry['pos'][0]\n",
    "    if isinstance(first_pos, list) and len(first_pos) >= 2:\n",
    "        doc_id = first_pos[1]\n",
    "        if doc_id in id2doc:\n",
    "            print(f\"\\n✅ Mapped document ID '{doc_id}' to text:\")\n",
    "            print(f\"Document text (first 200 chars): {id2doc[doc_id][:200]}...\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️ Document ID '{doc_id}' not found in BRIGHT mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450374f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Biology domain extracted:\n",
      "  - Corpus: 57359 documents\n",
      "  - Queries: 103 queries\n",
      "  - Qrels: 372 relevance judgments\n",
      "Sample query: ## Essential Problem:\n",
      "\n",
      "The article claims that insects are not attracted to light sources solely due to heat radiation. However, the user argues that insects could be evolutionarily programmed to associate light with heat, potentially explaining their attraction to LEDs despite the lack of significant heat emission.\n",
      "\n",
      "## Relevant Information:\n",
      "\n",
      "* **Insect vision:** Insects have compound eyes, which differ from the lens-based eyes of humans and other vertebrates. Compound eyes are highly sensitive to movement and light intensity, but have lower resolution and are less adept at distinguishing colors.\n",
      "* **Evolutionary history:** Insects have existed for hundreds of millions of years, evolving alongside various light sources like the sun, moon, and bioluminescent organisms.\n",
      "* **Light and heat association:** In nature, sunlight is often accompanied by heat, creating a natural association between the two stimuli. This association could be ingrained in insect behavior through evolution.\n",
      "* **LEDs and insect attraction:** LEDs emit negligible heat compared to traditional light sources, yet still attract insects. This suggests that heat alone cannot explain the phenomenon.\n",
      "\n",
      "## Addressing the User's Argument:\n",
      "\n",
      "The user's argument that insects might be \"expecting\" heat near LEDs due to an evolutionary association with light and heat is a valid point. Several lines of evidence support this idea:\n",
      "\n",
      "* **Behavioral experiments:** Studies have shown that insects exhibit positive phototaxis (movement towards light) even when the light source is not associated with a reward like food or warmth. This suggests an innate attraction to light.\n",
      "* **Physiological responses:** Research indicates that exposure to light can trigger physiological changes in insects, including increased activity and altered hormone levels. These changes could be related to an anticipation of warmth or other benefits associated with light.\n",
      "* **Evolutionary trade-offs:** While the attraction to light might be disadvantageous near artificial light sources like LEDs, it could be beneficial in natural environments for finding food, mates, or suitable habitats. The potential benefits might outweigh the occasional risks.\n",
      "\n",
      "## Conclusion:\n",
      "\n",
      "While the exact mechanisms underlying insect attraction to light remain under investigation, the user's suggestion that insects could be evolutionarily programmed to associate light with heat offers a plausible explanation. Further research is needed to fully understand the complex interplay between light, heat, and insect behavior. \n",
      "\n",
      "Sample corpus doc:  pelvises; and proportionally shorter forearms and forelegs.\n",
      "Based on 45 Neanderthal long bones from...\n"
     ]
    }
   ],
   "source": [
    "# Extract biology domain data\n",
    "biology_data = loader.get_data_split('biology')\n",
    "\n",
    "print(f\"✅ Biology domain extracted:\")\n",
    "print(f\"  - Corpus: {len(biology_data['corpus'])} documents\")\n",
    "print(f\"  - Queries: {len(biology_data['queries'])} queries\")\n",
    "print(f\"  - Qrels: {len(biology_data['qrels'])} relevance judgments\")\n",
    "print(f\"Sample query: {biology_data['queries'].iloc[0]['query']}\")\n",
    "print(f\"Sample corpus doc: {biology_data['corpus'].iloc[0]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6a6b7",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess to Tevatron JSONL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868b9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step 3A: Preparing ReasonIR-HQ training data...\n",
      "================================================================================\n",
      "Preparing ReasonIR-HQ training data...\n",
      "Loading ReasonIR dataset: reasonir/reasonir-data (subset: hq)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f3f2fec0ab4e838f0f4e5771bbfac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping document IDs to texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03cf253dabe4a419559b80d0337f925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting training data to data/processed/train_reasonir.jsonl...\n",
      "Saved 100521 training examples to data/processed/train_reasonir.jsonl\n",
      "\n",
      "✅ ReasonIR-HQ training data saved to: data/processed/train_reasonir.jsonl\n",
      "\n",
      "================================================================================\n",
      "Step 3B: Preparing BRIGHT evaluation data (biology domain)...\n",
      "================================================================================\n",
      "Processing 57359 documents for biology_corpus.jsonl...\n",
      "Processing 103 queries for biology_queries.jsonl...\n",
      "Saved TREC qrels to data/processed/biology_qrels.txt\n",
      "\n",
      "✅ BRIGHT evaluation files created:\n",
      "  - data/processed/biology_corpus.jsonl\n",
      "  - data/processed/biology_queries.jsonl\n",
      "  - data/processed/biology_qrels.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Prepare ReasonIR-HQ Training Data and BRIGHT Evaluation Data\n",
    "from data.preprocessor import BRIGHTPreprocessor\n",
    "\n",
    "preprocessor = BRIGHTPreprocessor(output_dir='data/processed')\n",
    "\n",
    "# Step 3A: Prepare ReasonIR-HQ training data\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 3A: Preparing ReasonIR-HQ training data...\")\n",
    "print(\"=\" * 80)\n",
    "reasonir_config = config['dataset']['reasonir']\n",
    "train_path = preprocessor.prepare_reasonir_hq_train_data(\n",
    "    id2doc=id2doc,\n",
    "    dataset_name=reasonir_config['name'],\n",
    "    subset=reasonir_config['subset'],\n",
    "    cache_dir=reasonir_config.get('cache_dir'),\n",
    "    filename='train_reasonir.jsonl'\n",
    ")\n",
    "print(f\"\\n✅ ReasonIR-HQ training data saved to: {train_path}\")\n",
    "\n",
    "# Step 3B: Prepare BRIGHT evaluation data (for a domain)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 3B: Preparing BRIGHT evaluation data (biology domain)...\")\n",
    "print(\"=\" * 80)\n",
    "biology_data = loader.get_data_split('biology')\n",
    "\n",
    "corpus_path = preprocessor.prepare_tevatron_corpus(\n",
    "    biology_data['corpus'],\n",
    "    'biology_corpus.jsonl'\n",
    ")\n",
    "\n",
    "queries_path = preprocessor.prepare_tevatron_queries(\n",
    "    biology_data['queries'],\n",
    "    'biology_queries.jsonl'\n",
    ")\n",
    "\n",
    "qrels_path = preprocessor.prepare_trec_qrels(\n",
    "    biology_data['qrels'],\n",
    "    'biology_qrels.txt'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ BRIGHT evaluation files created:\")\n",
    "print(f\"  - {corpus_path}\")\n",
    "print(f\"  - {queries_path}\")\n",
    "print(f\"  - {qrels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63c90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Verifying ReasonIR-HQ training data format...\n",
      "================================================================================\n",
      "\n",
      "Sample ReasonIR-HQ training entry:\n",
      "Query ID: reasonir_0\n",
      "Query (first 200 chars): A researcher is analyzing a sound signal represented by the equation f(t) = 2sin(3πt) + sin(5πt) + 0.5sin(7πt). Using the Fourier transform, what are the frequencies, amplitudes, and phases of the ind...\n",
      "Number of positives: 1\n",
      "First positive (first 200 chars): A sound signal is given by the equation f(t) = sin(2πt) + sin(4πt) + sin(6πt) where t is time in seconds. Use Fourier transform to find the frequencies, amplitudes, and phases of the individual sinuso...\n",
      "Negatives: []\n",
      "\n",
      "================================================================================\n",
      "Verifying BRIGHT evaluation data format...\n",
      "================================================================================\n",
      "\n",
      "Sample BRIGHT corpus entry:\n",
      "Doc ID: neanderthals_vitamin_C_diet/Neanderthal_0_43.txt\n",
      "Text (first 200 chars):  pelvises; and proportionally shorter forearms and forelegs.\n",
      "Based on 45 Neanderthal long bones from 14 men and 7 women, the average height was 164 to 168 cm (5 ft 5 in to 5 ft 6 in) for males and 152...\n",
      "\n",
      "Sample BRIGHT query entry:\n",
      "Query ID: 0\n",
      "Query (first 200 chars): ## Essential Problem:\n",
      "\n",
      "The article claims that insects are not attracted to light sources solely due to heat radiation. However, the user argues that insects could be evolutionarily programmed to asso...\n",
      "\n",
      "✅ All data formats verified!\n"
     ]
    }
   ],
   "source": [
    "# Verify JSONL format\n",
    "import json\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Verifying ReasonIR-HQ training data format...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nSample ReasonIR-HQ training entry:\")\n",
    "with open(train_path, 'r') as f:\n",
    "    sample_train = json.loads(f.readline())\n",
    "    print(f\"Query ID: {sample_train['query_id']}\")\n",
    "    print(f\"Query (first 200 chars): {sample_train['query'][:200]}...\")\n",
    "    print(f\"Number of positives: {len(sample_train['positives'])}\")\n",
    "    print(f\"First positive (first 200 chars): {sample_train['positives'][0][:200]}...\")\n",
    "    print(f\"Negatives: {sample_train['negatives']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Verifying BRIGHT evaluation data format...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nSample BRIGHT corpus entry:\")\n",
    "with open(corpus_path, 'r') as f:\n",
    "    sample_corpus = json.loads(f.readline())\n",
    "    print(f\"Doc ID: {sample_corpus['id']}\")\n",
    "    print(f\"Text (first 200 chars): {sample_corpus['text'][:200]}...\")\n",
    "\n",
    "print(\"\\nSample BRIGHT query entry:\")\n",
    "with open(queries_path, 'r') as f:\n",
    "    sample_query = json.loads(f.readline())\n",
    "    print(f\"Query ID: {sample_query['id']}\")\n",
    "    print(f\"Query (first 200 chars): {sample_query['text'][:200]}...\")\n",
    "\n",
    "print(\"\\n✅ All data formats verified!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
